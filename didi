import streamlit as st
import os
import json
import pickle
import pandas as pd
import numpy as np
from tqdm import tqdm
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import boto3
import botocore
from pprint import pprint
import faiss
from utils import experience_score, work_type_match, language_score_fraction, education_matches, preprocess_resume
import sqlite3
from concurrent.futures import ThreadPoolExecutor

st.set_page_config(
    page_title="–ü–æ–¥–±–æ—Ä —Ä–µ–∑—é–º–µ",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("–ü–æ–¥–±–æ—Ä —Ä–µ–∑—é–º–µ –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—é")
st.markdown("---")

fields = {
    '–ì—Ä–∞—Ñ–∏–∫ —Ä–∞–±–æ—Ç—ã': '5/2',
    '–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É—Å–ª–æ–≤–∏—è': '',
    '–ó–Ω–∞–Ω–∏–µ —è–∑—ã–∫–æ–≤': ['–†—É—Å—Å–∫–∏–π', '–∫–∞–∑–∞—Ö—Å–∫–∏–π'],
    '–î–æ–ª–∂–Ω–æ—Å—Ç—å': '-',
    '–ù–∞–≤—ã–∫–∏/–∑–Ω–∞–Ω–∏—è': [
        '–ù–∞–≤—ã–∫–∏ —Ä–∞–±–æ—Ç—ã –Ω–∞ —É—Ä–æ–≤–Ω–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å SQL.',
        '–£–º–µ–Ω–∏—è –∏ –Ω–∞–≤—ã–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞—Ç—å –≤ —Å—Ä–µ–¥–µ Jupyter –Ω–∞ —è–∑—ã–∫–µ Python (pandas, numpy, seaborn / matplotlib, nltk, spaCy, transformers).',
        '–û—Å–Ω–æ–≤—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏ —Ç–µ–æ—Ä–∏–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π.',
        '–ë–∞–∑–æ–≤—ã–µ –∑–Ω–∞–Ω–∏—è –≤ –æ–±–ª–∞—Å—Ç–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.'
    ],
    '–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ': '-',
    '–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã': '-',
    '–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –ø–æ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏': [
        '–†–∞–∑—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏ –≤–Ω–µ–¥—Ä—è–µ—Ç NLP –º–æ–¥–µ–ª–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.',
        '–ü—Ä–æ–≤–æ–¥–∏—Ç –æ—Ü–µ–Ω–∫—É –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –º–æ–¥–µ–ª–µ–π NLP –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –∏—Ö —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏.',
        '–£–º–µ–Ω–∏—è –∏ –Ω–∞–≤—ã–∫–∏ –≤—ã—è–≤–ª—è—Ç—å –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏ –±–∏–∑–Ω–µ—Å–∞ –≤ –æ–±–ª–∞—Å—Ç–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞ (NLP).'
    ]
}

with st.form(key="requirements_form"):
    st.subheader("–ó–∞–ø–æ–ª–Ω–∏—Ç–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏")
    user_inputs = {}
    for label, default in fields.items():
        if isinstance(default, list):
            text = st.text_area(
                label,
                value="\n".join(default),
                help="–í–≤–µ–¥–∏—Ç–µ –∫–∞–∂–¥–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏"
            )
            user_inputs[label] = [
                item.strip()
                for line in text.splitlines()
                for item in line.split(',')
                if item.strip()
            ]
        else:
            user_inputs[label] = st.text_input(label, value=default)

    submit = st.form_submit_button("üîç –ü–æ–¥–æ–±—Ä–∞—Ç—å —Ä–µ–∑—é–º–µ")
job_req = user_inputs

MODEL_NAME = 'model1'
model = SentenceTransformer(MODEL_NAME, device='cpu')

os.environ["http_proxy"] = ""
os.environ["https_proxy"] = ""

@st.cache_data
def preload_embeddings(desc_cache, skill_cache):
    desc_emb = {}
    skill_emb = {}
    for fn in os.listdir(desc_cache):
        rid = fn.replace('.pkl', '')
        with open(os.path.join(desc_cache, fn), 'rb') as f:
            desc_emb[rid] = pickle.load(f)
    for fn in os.listdir(skill_cache):
        rid = fn.replace('.pkl', '')
        with open(os.path.join(skill_cache, fn), 'rb') as f:
            skill_emb[rid] = pickle.load(f)
    return desc_emb, skill_emb

@st.cache_data
def load_resumes(db_path, table_name):
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    cursor.execute(f'SELECT resume_json FROM {table_name}')
    rows = cursor.fetchall()
    conn.close()
    return [json.loads(row[0]) for row in rows]

def score_resume(x):
    rid = x['id']
    if not any(title.lower() in x.get('position', '').lower() for title in target_titles):
        return None

    score = 0
    skills_fit = 0

    score += weights['year_exp'] * experience_score(job_req['–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã'], x.get('experience_months', '0'))

    desc_embs = resume_descs.get(rid, [])
    if desc_embs:
        best_fit = max(
            float(cosine_similarity(req_desc_emb, sent).max(axis=1).mean())
            for sent in desc_embs
        )
        score += weights['exp'] * best_fit

    skill_np = resume_skills.get(rid)
    if skill_np is not None:
        skills_fit = float(cosine_similarity(req_skill_emb, skill_np).max(axis=1).mean())
        score += weights['skills'] * skills_fit

    if work_type_match(job_req['–ì—Ä–∞—Ñ–∏–∫ —Ä–∞–±–æ—Ç—ã'], x.get('work_type', [])) == 0:
        return None

    lang_score = language_score_fraction(job_req['–ó–Ω–∞–Ω–∏–µ —è–∑—ã–∫–æ–≤'], x.get('languages', {}))
    score += weights['lang_score'] * lang_score

    if x.get('education'):
        score += weights['edu_score'] * education_matches(job_req['–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ'], x['education'])

    x['score'] = round(score, 2)
    x['skills_fit'] = round(skills_fit * weights['skills'], 2)
    return x

if submit:
    with st.spinner("–ò–¥—ë—Ç –ø–æ–¥–±–æ—Ä —Ä–µ–∑—é–º–µ..."):
        job_req = user_inputs
        job_descs = job_req['–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –ø–æ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏']
        job_skills = job_req['–ù–∞–≤—ã–∫–∏/–∑–Ω–∞–Ω–∏—è']
        target_titles = job_req['–î–æ–ª–∂–Ω–æ—Å—Ç—å']

        req_desc_emb = model.encode(job_descs, convert_to_numpy=True, batch_size=256)
        req_skill_emb = model.encode(job_skills, convert_to_numpy=True, batch_size=256)

        resume_descs, resume_skills = preload_embeddings('desc_embeddings', 'skill_embeddings')
        resumes = load_resumes('resumes.db', 'processed_resumes')

        # -------- Parallel Scoring --------
        weights = {
            'year_exp' : 15,
            'exp'      : 40,
            'skills'   : 30,
            'lang_score': 5,
            'edu_score': 10
        }

        with ThreadPoolExecutor() as executor:
            results = list(executor.map(score_resume, resumes))
            results = [r for r in results if r]

        final_res = sorted(results, key=lambda x: -x['skills_fit'])[:20]
        
        VPC_ENDPOINT_URL = "https://vpce-020ae5d25917d44a7-4jbuf238.bedrock-runtime.eu-central-1.vpce.amazonaws.com"
        bedrock_runtime = boto3.client(
                    'bedrock-runtime',
                    endpoint_url=VPC_ENDPOINT_URL,
                    region_name="eu-central-1", 
                    verify=False
                )
        
        def aws_score_candidate(candidate):
            prompt_data = f"""  
            –¢—ã –∫—Ä—É—Ç–æ–π hr, –∫–æ—Ç–æ—Ä—ã–π –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ä–µ–∑—é–º–µ —Å–º–æ—Ç—Ä—è –Ω–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –æ—Ç 0 –¥–æ 100, –µ—Å–ª–∏ –∫–∞–∫–∏–µ-—Ç–æ –≤–∞–∂–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –Ω–µ –ø–æ–¥—Ö–æ–¥—è—Ç - —Å—Ä–∞–∑—É —Å—Ç–∞–≤—å 0.
            –û—Å–æ–±–µ–Ω–Ω–æ —Ç—ã —Å–º–æ—Ç—Ä–∏—à—å –Ω–∞ '–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –ø–æ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏' –≤ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è—Ö –∏ –Ω–∞ experience –≤ —Ä–µ–∑—é–º–µ. 
            –ö–∞–Ω–¥–∏–¥–∞—Ç –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å –æ–ø—ã—Ç —á–µ—Ç–∫–æ —Ç–∞–∫–æ–π –∫–∞–∫ –Ω–∞–ø–∏—Å–∞–Ω–æ –≤ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è.
            –¢—ã –¥–æ–ª–∂–µ–Ω –ø—Ä–æ—Å—Ç–æ –≤–µ—Ä–Ω—É—Ç—å –æ—Ü–µ–Ω–∫—É –±–µ–∑ –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤ –∏ –æ–ø–∏—Å–∞–Ω–∏–π.
        
            –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
            {str(job_req)}
        
            –†–µ–∑—é–º–µ:
            {str(candidate)}
            """
        
            try:
                body = json.dumps({
                    "anthropic_version": "bedrock-2023-05-31",
                    "max_tokens": 100,
                    "temperature": 0,
                    "top_k": 250,
                    "top_p": 0.99,
                    "messages": [{"role": "user", "content": [{"type": "text", "text": prompt_data}]}]
                })
        
                response = bedrock_runtime.invoke_model(
                    body=body,
                    modelId='eu.anthropic.claude-3-7-sonnet-20250219-v1:0',
                    accept="application/json",
                    contentType="application/json"
                )
        
                content = json.loads(response.get("body").read())["content"][0]["text"]
                candidate['aws_score'] = int(content.strip())
                return candidate
        
            except Exception as e:
                candidate['aws_score'] = 0
                return candidate
        
        # üîÑ Score top candidates with AWS
        with st.spinner("–û—Ü–µ–Ω–∫–∞ —Ä–µ–∑—é–º–µ —á–µ—Ä–µ–∑ AWS..."):
            with ThreadPoolExecutor() as executor:
                aws_evaluated = list(executor.map(aws_score_candidate, final_res))
        
            aws_evaluated = sorted(aws_evaluated, key=lambda x: -x['aws_score'])
        
            st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ —á–µ—Ä–µ–∑ AWS")
            for i, cand in enumerate(aws_evaluated):
                st.write(f"–ö–∞–Ω–¥–∏–¥–∞—Ç #{i + 1}")
                st.write(cand)
